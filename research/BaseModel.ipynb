{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b87ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ea3287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\NARINDER\\\\Desktop\\\\new project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ad460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c86e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\NARINDER\\\\Desktop\\\\new project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caecba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47ca801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "from src.floodClassifier.constants import *\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path = CONFIG_FILE_PATH, params_path = PARAMS_FILE_PATH):\n",
    "        self.config_path = Path(config_path)\n",
    "        self.params_path = Path(params_path)\n",
    "        if not self.config_path.exists():\n",
    "            raise FileNotFoundError(f\"Config file not found: {self.config_path}\")\n",
    "        if not self.params_path.exists():\n",
    "            raise FileNotFoundError(f\"Params file not found: {self.params_path}\")\n",
    "        self._config = yaml.safe_load(self.config_path.read_text())\n",
    "        self._params = yaml.safe_load(self.params_path.read_text())\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> Dict[str, Any]:\n",
    "        pb = self._config.get(\"prepare_base_model\", {})\n",
    "        return {\n",
    "            \"root_dir\": pb.get(\"root_dir\", \"artifacts/prepareBaseModel\"),\n",
    "            \"base_model_path\": pb.get(\"base_model_path\", \"artifacts/prepareBaseModel/base_model.pkl\")\n",
    "        }\n",
    "\n",
    "    def get_arima_params(self) -> Dict[str, Any]:\n",
    "        model_cfg = self._params.get(\"MODEL\", {})\n",
    "        tuning_cfg = self._params.get(\"TUNING\", {})\n",
    "        forecast_cfg = self._params.get(\"FORECAST\", {})\n",
    "        metrics = self._params.get(\"METRICS\", [])\n",
    "        return {\n",
    "            \"type\": model_cfg.get(\"TYPE\", \"arima\"),\n",
    "            \"p\": int(model_cfg.get(\"P\", 1)),\n",
    "            \"d\": int(model_cfg.get(\"D\", 0)),\n",
    "            \"q\": int(model_cfg.get(\"Q\", 0)),\n",
    "            \"seasonal\": bool(model_cfg.get(\"SEASONAL\", False)),\n",
    "            \"m\": int(model_cfg.get(\"M\", 0)),\n",
    "            \"enforce_stationarity\": bool(model_cfg.get(\"ENFORCE_STATIONARITY\", True)),\n",
    "            \"enforce_invertibility\": bool(model_cfg.get(\"ENFORCE_INVERTIBILITY\", True)),\n",
    "            \"tuning_enabled\": bool(tuning_cfg.get(\"ENABLED\", False)),\n",
    "            \"tuning_search\": tuning_cfg.get(\"SEARCH\", \"grid\"),\n",
    "            \"p_values\": tuning_cfg.get(\"P_VALUES\", []),\n",
    "            \"d_values\": tuning_cfg.get(\"D_VALUES\", []),\n",
    "            \"q_values\": tuning_cfg.get(\"Q_VALUES\", []),\n",
    "            \"horizon\": int(forecast_cfg.get(\"HORIZON\", 30)),\n",
    "            \"conf_int\": float(forecast_cfg.get(\"CONF_INT\", 0.95)),\n",
    "            \"metrics\": metrics\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e468ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from typing import Optional, Dict\n",
    "\n",
    "class PrepareBaseModel:\n",
    "    def __init__(self, prepare_cfg: Dict[str, str], arima_params: Dict[str, any]):\n",
    "        self.root_dir = Path(prepare_cfg[\"root_dir\"])\n",
    "        self.base_model_path = Path(prepare_cfg[\"base_model_path\"])\n",
    "        self.arima_params = arima_params\n",
    "        os.makedirs(self.root_dir, exist_ok=True)\n",
    "\n",
    "    def _ensure_series(self, y: pd.Series) -> pd.Series:\n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y)\n",
    "        if y.index.dtype == object:\n",
    "            try:\n",
    "                y.index = pd.to_datetime(y.index)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return y.astype(float)\n",
    "\n",
    "    def build_arima(self, y: pd.Series, exog: Optional[pd.DataFrame] = None):\n",
    "        y = self._ensure_series(y)\n",
    "        p = self.arima_params[\"p\"]\n",
    "        d = self.arima_params[\"d\"]\n",
    "        q = self.arima_params[\"q\"]\n",
    "        seasonal = self.arima_params[\"seasonal\"]\n",
    "        m = self.arima_params[\"m\"] if seasonal else 0\n",
    "\n",
    "        model = SARIMAX(\n",
    "            endog=y,\n",
    "            exog=exog,\n",
    "            order=(p, d, q),\n",
    "            seasonal_order=(0, 0, 0, 0) if not seasonal else (p, d, q, m),\n",
    "            enforce_stationarity=self.arima_params.get(\"enforce_stationarity\", True),\n",
    "            enforce_invertibility=self.arima_params.get(\"enforce_invertibility\", True),\n",
    "            simple_differencing=False\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit_and_save(self, y: pd.Series, exog: Optional[pd.DataFrame] = None, save_overwrite: bool = True):\n",
    "        model = self.build_arima(y, exog=exog)\n",
    "        fitted = model.fit(disp=False)\n",
    "        if self.base_model_path.exists() and not save_overwrite:\n",
    "            raise FileExistsError(f\"Base model already exists at {self.base_model_path}\")\n",
    "        with open(self.base_model_path, \"wb\") as f:\n",
    "            pickle.dump(fitted, f)\n",
    "        return fitted\n",
    "\n",
    "    def load(self):\n",
    "        if not self.base_model_path.exists():\n",
    "            raise FileNotFoundError(f\"No base model at {self.base_model_path}\")\n",
    "        with open(self.base_model_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def run_from_df(self, df: pd.DataFrame, target_col: str = \"y\", exog_cols: Optional[list] = None):\n",
    "        if target_col not in df.columns:\n",
    "            raise KeyError(f\"target_col '{target_col}' not found in dataframe\")\n",
    "        y = df[target_col]\n",
    "        exog = df[exog_cols] if exog_cols else None\n",
    "        fitted = self.fit_and_save(y, exog=exog)\n",
    "        return fitted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9cbfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NARINDER\\AppData\\Local\\Temp\\ipykernel_604\\1717932242.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[exog_cols] = df[exog_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "c:\\Users\\NARINDER\\Desktop\\new project\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\NARINDER\\Desktop\\new project\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-21 02:55:22,635: INFO: 1717932242: ARIMA base model fitted and saved to: artifacts/prepareBaseModel/base_model.h5]\n"
     ]
    }
   ],
   "source": [
    "from src.floodClassifier import logger\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_cfg = config.get_prepare_base_model_config()\n",
    "    arima_params = config.get_arima_params()\n",
    "    preparer = PrepareBaseModel(prepare_cfg, arima_params)\n",
    "\n",
    "    csv_path = r\"artifacts\\data_ingestion\\FloodPrediction.csv\"\n",
    "\n",
    "    date_year_col = \"Year\"\n",
    "    date_month_col = \"Month\"\n",
    "    target_col = \"Flood?\"\n",
    "    exog_cols = [\"Rainfall\", \"Max_Temp\", \"Min_Temp\", \"Relative_Humidity\"]\n",
    "    usecols = [date_year_col, date_month_col, target_col] + exog_cols\n",
    "    df = pd.read_csv(csv_path, usecols=usecols)\n",
    "\n",
    "    try:\n",
    "        df[\"Month\"] = df[date_month_col].astype(int)\n",
    "        df[\"Year\"] = df[date_year_col].astype(int)\n",
    "        df[\"_date\"] = pd.to_datetime(dict(year=df[\"Year\"], month=df[\"Month\"], day=1))\n",
    "    except Exception:\n",
    "        df[\"_date\"] = pd.to_datetime(df[date_year_col].astype(str) + \"-\" + df[date_month_col].astype(str) + \"-01\", errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"_date\"]).copy()\n",
    "    df = df.set_index(\"_date\")\n",
    "    df = df.sort_index()\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        raise KeyError(f\"Target column '{target_col}' not found in file: {csv_path}\")\n",
    "\n",
    "    df = df.dropna(subset=[target_col])\n",
    "\n",
    "    df[target_col] = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
    "    if df[target_col].isna().any():\n",
    "        raise ValueError(\"Target column contains non-numeric or uncoercible values after parsing\")\n",
    "\n",
    "    if exog_cols:\n",
    "        for col in exog_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df[exog_cols] = df[exog_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df = df.sort_index()\n",
    "\n",
    "    required_obs = max(arima_params.get(\"p\", 1), arima_params.get(\"d\", 0), arima_params.get(\"q\", 1)) + 1\n",
    "    if len(df) < required_obs:\n",
    "        raise ValueError(f\"Not enough observations ({len(df)}) to fit ARIMA with order p,d,q requiring at least {required_obs}\")\n",
    "\n",
    "    fitted_model = preparer.run_from_df(df, target_col=target_col, exog_cols=exog_cols)\n",
    "    logger.info(f\"ARIMA base model fitted and saved to: {prepare_cfg['base_model_path']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a261370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG pre-align lengths -> y_test: 898 y_pred: 915\n",
      "DEBUG pre-align index ranges -> y_test: 2004-07-01 00:00:00 to 2013-12-01 00:00:00\n",
      "DEBUG y_pred index sample: DatetimeIndex(['2004-07-01', '2004-07-01', '2004-07-01'], dtype='datetime64[ns]', name='_date', freq=None) len: 915\n",
      "Evaluated samples: 898\n",
      "MAE: 0.2438\n",
      "RMSE: 0.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NARINDER\\AppData\\Local\\Temp\\ipykernel_604\\4154752488.py:33: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[exog_cols] = df[exog_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "c:\\Users\\NARINDER\\Desktop\\new project\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\NARINDER\\Desktop\\new project\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from src.floodClassifier.constants import *\n",
    "\n",
    "config = ConfigurationManager()\n",
    "prepare_cfg = config.get_prepare_base_model_config()\n",
    "arima_params = config.get_arima_params()\n",
    "\n",
    "base_model_path = Path(prepare_cfg[\"base_model_path\"])\n",
    "csv_path = r\"C:\\Users\\NARINDER\\Desktop\\new project\\artifacts\\data_ingestion\\FloodPrediction.csv\"\n",
    "\n",
    "date_year_col = \"Year\"\n",
    "date_month_col = \"Month\"\n",
    "target_col = \"Flood?\"\n",
    "exog_cols = [\"Rainfall\", \"Max_Temp\"]\n",
    "test_fraction = 0.2\n",
    "forecast_horizon = arima_params.get(\"horizon\", 30)\n",
    "\n",
    "df = pd.read_csv(csv_path, usecols=[date_year_col, date_month_col, target_col] + exog_cols)\n",
    "df[\"Month\"] = df[date_month_col].astype(int)\n",
    "df[\"Year\"] = df[date_year_col].astype(int)\n",
    "df[\"_date\"] = pd.to_datetime(dict(year=df[\"Year\"], month=df[\"Month\"], day=1))\n",
    "df = df.dropna(subset=[\"_date\"])\n",
    "df = df.set_index(\"_date\").sort_index()\n",
    "df[target_col] = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
    "df = df.dropna(subset=[target_col])\n",
    "if exog_cols:\n",
    "    for c in exog_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df[exog_cols] = df[exog_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "n = len(df)\n",
    "n_test = max(1, int(n * test_fraction))\n",
    "train_df = df.iloc[:-n_test]\n",
    "test_df = df.iloc[-n_test:]\n",
    "\n",
    "y_train = train_df[target_col]\n",
    "y_test = test_df[target_col]\n",
    "exog_train = train_df[exog_cols] if exog_cols else None\n",
    "exog_test = test_df[exog_cols] if exog_cols else None\n",
    "\n",
    "if not base_model_path.exists():\n",
    "    raise FileNotFoundError(f\"Base model not found at {base_model_path}\")\n",
    "\n",
    "with open(base_model_path, \"rb\") as f:\n",
    "    fitted = pickle.load(f)\n",
    "\n",
    "steps = len(test_df)\n",
    "try:\n",
    "    fc = fitted.get_forecast(steps=steps, exog=exog_test)\n",
    "    y_pred = fc.predicted_mean\n",
    "    conf_int = fc.conf_int(alpha=1 - arima_params.get(\"conf_int\", 0.95))\n",
    "except Exception:\n",
    "    start = test_df.index[0]\n",
    "    end = test_df.index[-1]\n",
    "    y_pred = fitted.predict(start=start, end=end, exog=exog_test)\n",
    "    conf_int = None\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "try:\n",
    "    y_pred = pd.Series(y_pred)\n",
    "except Exception:\n",
    "    y_pred = pd.Series(list(y_pred))\n",
    "\n",
    "print(\"DEBUG pre-align lengths -> y_test:\", len(y_test), \"y_pred:\", len(y_pred))\n",
    "try:\n",
    "    print(\"DEBUG pre-align index ranges -> y_test:\", y_test.index.min(), \"to\", y_test.index.max())\n",
    "except Exception:\n",
    "    print(\"DEBUG y_test has no index\")\n",
    "try:\n",
    "    print(\"DEBUG y_pred index sample:\", getattr(y_pred, \"index\", None)[:3], \"len:\", len(y_pred))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    y_pred_idx = pd.Series(y_pred.values, index=test_df.index)\n",
    "except Exception:\n",
    "    y_pred_idx = pd.Series(y_pred.values[:len(test_df)], index=test_df.index[:len(y_pred.values[:len(test_df)])])\n",
    "\n",
    "y_test_s = y_test.astype(float)\n",
    "\n",
    "combined = pd.concat([y_test_s, y_pred_idx], axis=1)\n",
    "combined.columns = [\"y_true\", \"y_pred\"]\n",
    "combined = combined.dropna(how=\"any\")\n",
    "\n",
    "if combined.empty:\n",
    "    print(\"DEBUG: index alignment produced empty combined. Trying positional fallback.\")\n",
    "    min_len = min(len(y_test_s), len(y_pred))\n",
    "    if min_len > 0:\n",
    "        y_true_pos = y_test_s.values[-min_len:].astype(float)\n",
    "        y_pred_pos = y_pred.values[-min_len:].astype(float)\n",
    "        combined = pd.DataFrame({\"y_true\": y_true_pos, \"y_pred\": y_pred_pos})\n",
    "    else:\n",
    "        combined = pd.DataFrame()\n",
    "\n",
    "if combined.empty:\n",
    "    print(\"DEBUG: positional fallback produced empty. Trying element-wise non-NaN overlap.\")\n",
    "    a = y_test_s.values\n",
    "    b = y_pred.values\n",
    "    min_len = min(len(a), len(b))\n",
    "    if min_len > 0:\n",
    "        a = a[-min_len:]\n",
    "        b = b[-min_len:]\n",
    "        mask = np.isfinite(a) & np.isfinite(b)\n",
    "        if mask.any():\n",
    "            combined = pd.DataFrame({\"y_true\": a[mask], \"y_pred\": b[mask]})\n",
    "        else:\n",
    "            combined = pd.DataFrame()\n",
    "\n",
    "if combined.empty:\n",
    "    print(\"DEBUG: final diagnostics -> len(y_test):\", len(y_test), \"len(y_pred):\", len(y_pred))\n",
    "    print(\"DEBUG sample y_test tail:\", y_test.tail(5))\n",
    "    print(\"DEBUG sample y_pred tail:\", pd.Series(y_pred).tail(5))\n",
    "    raise ValueError(\"No overlapping non-NaN samples available for evaluation after all fallbacks\")\n",
    "\n",
    "y_true = combined[\"y_true\"].astype(float).values\n",
    "y_pred_vals = combined[\"y_pred\"].astype(float).values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred_vals)\n",
    "rmse = mean_squared_error(y_true, y_pred_vals)\n",
    "\n",
    "print(f\"Evaluated samples: {len(y_true)}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# future_steps = min(forecast_horizon, 12)\n",
    "# if exog_cols:\n",
    "#     last_exog = df[exog_cols].iloc[-1:]\n",
    "#     future_exog = pd.concat([last_exog]*future_steps, ignore_index=True)\n",
    "#     future_index = pd.date_range(start=df.index[-1] + pd.offsets.MonthBegin(1), periods=future_steps, freq=\"MS\")\n",
    "#     future_exog.index = future_index\n",
    "# else:\n",
    "#     future_exog = None\n",
    "#     future_index = pd.date_range(start=df.index[-1] + pd.offsets.MonthBegin(1), periods=future_steps, freq=\"MS\")\n",
    "\n",
    "# try:\n",
    "#     future_fc = fitted.get_forecast(steps=future_steps, exog=future_exog)\n",
    "#     future_pred = pd.Series(future_fc.predicted_mean.values, index=future_index)\n",
    "#     future_ci = future_fc.conf_int(alpha=1 - arima_params.get(\"conf_int\", 0.95))\n",
    "# except Exception:\n",
    "#     future_pred = pd.Series(fitted.predict(start=future_index[0], end=future_index[-1], exog=future_exog),\n",
    "#                             index=future_index)\n",
    "#     future_ci = None\n",
    "\n",
    "# print(\"\\nFuture predictions (quick):\")\n",
    "# print(future_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf1232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# prob = np.clip(y_pred, 0.0, 1.0)\n",
    "# pred_label = (prob >= 0.5).astype(int)\n",
    "# true_label = y_test.astype(int)\n",
    "\n",
    "# print(\"accuracy\", accuracy_score(true_label, pred_label))\n",
    "# print(\"precision\", precision_score(true_label, pred_label, zero_division=0))\n",
    "# print(\"recall\", recall_score(true_label, pred_label, zero_division=0))\n",
    "# print(\"f1\", f1_score(true_label, pred_label, zero_division=0))\n",
    "# print(\"confusion:\\n\", confusion_matrix(true_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac86c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
